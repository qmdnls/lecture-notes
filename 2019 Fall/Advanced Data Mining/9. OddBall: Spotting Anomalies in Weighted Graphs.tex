% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------
 
\documentclass[12pt]{article}
 
\usepackage[margin=0.7in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}

% times new roman
%\usepackage{newtxtext,newtxmath}

% baskerville
\usepackage{Baskervaldx}
\usepackage[baskervaldx]{newtxmath} 
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{solution}{\begin{proof}[Solution]}{\end{proof}}

% utf-8
\usepackage[utf8]{inputenc}

% cite color
\usepackage[x11names]{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true,%
citecolor=DodgerBlue4,%
filecolor=blue,%
linkcolor=blue,%
urlcolor=blue
}

% line spacing
\renewcommand{\baselinestretch}{1.0}

% margin
\usepackage{geometry}
 \geometry{
 a4paper,
 left=20mm,
 right=20mm,
 top=20mm,
 bottom=20mm
}

% name and student ID in header
\usepackage{fancyhdr}
\pagestyle{fancy}

\fancyhead{}
\fancyhead[L]{Advanced Data Mining}
\fancyhead[C]{Bj√∂rn Bebensee (2019-21343)}
\fancyhead[R]{November 27, 2019}
\fancypagestyle{plain}{%  the preset of fancyhdr 
    \fancyfoot[C]{\textbf{\thepage}} % except the center
    \renewcommand{\headrulewidth}{0pt}
    \renewcommand{\footrulewidth}{0pt}}

% spacing in itemize environments
\usepackage{enumitem}
\setitemize{noitemsep,topsep=2pt,parsep=2pt,partopsep=2pt}

% misc hyphenation
\hyphenation{page-rank}

% fancyhdr headheight
\setlength{\headheight}{15pt}

\begin{document}
 
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

% ugly fake title hack
{\Large\centering
    \textbf{OddBall: Spotting Anomalies in Weighted Graphs}
\par}

\bigskip

\noindent
1. What is the problem that the paper wants to solve? Why is it difficult (related works)?

\begin{itemize}
    \item Given a large, weighted graph find nodes that are anomalies in the graph (unsupervised)
    \item Previous solutions focused on feature sin multidimensional space rather than graph features
\end{itemize}

\noindent
2. What is the solution? What is the main idea?

\begin{itemize}
    \item By looking at a node's \emph{egograph} (graph induced by a node's neighborhood) and its features we can identify anomalies
    \item Specifically degree of ego $N_i$, number of edges in the egonet $E_i$, total weight of edges in the egonet $W_i$ and the principal eigenvalue of the weighted adjacency matrix $\lambda_{w,i}$ of the egonet are the most effective features
    \item Additionally the authors find power laws for pairs of these features and flag nodes that deviate from these patterns ($E_i \propto N_i^\alpha$, $W_i \propto E_i^\beta$, $\lambda_{w,i} \propto W_i^\gamma$ and $W_{i,j} \propto R_{i,j}^\theta$)
\end{itemize}

\noindent
3. What is the result?

\begin{itemize}
    \item Able to find and score anomalies in weighted graphs in an unsupervised fashion
    \item Can classify the type of anomaly (\emph{CliqueStar}, \emph{HeavyVicincty} and \emph{DominantPair})
    \item The proposed method is scalable and works well on large graphs
    \item They study some of the anomalies found by the \emph{OddBall} algorithm across different datasets
\end{itemize}

\noindent
4. What is the main novelty that enabled the solution?

\begin{itemize}
    \item The main novelty are the power laws identified by the authors with respect to which they can then define outliers
    \item Proposed algorithm is scalable 
\end{itemize}

\noindent
5. What are the good aspects of the paper? Did you learn something from the paper?

\begin{itemize}
    \item Akoglu et al. do a very good job of qualitatively analyzing the results of their algorithm and identifying the different types of anomalies found by their algorithm as well as specific outlier instances (such as certain authors publishing mostly in a specific conference)
\end{itemize}

\noindent
6. What is the impact of the paper?

\begin{itemize}
    \item One of few papers in the field of unsupervised anomaly detection in (weighted) graphs, authors provide a good contribution that can find anomalies and the type of anomaly in a weighted graphs
\end{itemize}

\noindent
7. Are there weaknesses/missing parts in the paper? How can you improve it?

\begin{itemize}
    \item Missing quantitative analysis (one could evaluate approach on a labelled dataset for instance)
    \item The algorithm only really works for weighted graphs (although one may be able to find similarly useful patterns/laws in egographs of unweighted graphs)
\end{itemize}

\noindent
8. How can you extend the paper?

\begin{itemize}
    \item Authors propose to extend the paper to the time dimension, i.e. find anomalies over time
    \item Extend the algorithm for directed graphs (although briefly mentioned this is not explained in the paper), unweighted graphs, perhaps look at other sets of featuers/patterns in the data
\end{itemize}

\noindent
9. How can you apply the technique to other data/problems?

\begin{itemize}
    \item Find anomalies by first finding regularities and patterns in the data, then identify outliers and score them according to how often and how heavily they deviate from these patterns
\end{itemize}

\end{document}